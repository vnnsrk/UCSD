{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECE 289: Homework 3\n",
    "### Part (A): Networks Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 15 µs\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# import required packages\n",
    "# load results from HW1 to use. Otherwise, execute code from HW1 to produce results again.\n",
    "\n",
    "%time\n",
    "#import useful packages, all of them are important but not necessarily used in this code\n",
    "#enable inline plotting in Python Notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#supress warnings\n",
    "\n",
    "%pylab inline\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import scipy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use network datasets from the Public Data Folder. \n",
    "#### Please DO NOT copy dataset in your directory (or anywhere else!) because it will certainly result in 'timeout error' while submission. \n",
    "#### Now that we are familiar with Gephi and its usage, we will explore some built in tools from Gephi to improve our visualizations further. You will need results from the HW1. Only use results calculated using networkX here. This can be done by adding your results for node degree, centrality etc. as an attribute to the"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this task, we will use Filter tool in Gephi to threshold available network data, using various properties.\n",
    "#### Visualise Facebook Network, Enron Emails Network, Collaboration (Erdos) Network applying following thesholds. Make sure to have all the visualizations labelled with appropriate node labels. This is a quiet open ended question, as you have a lot of scope to make your visualizations better trying different layouts, colors etc. So, turn in the best visualization that you get in each case. You should attach an image(.png, .jpg) for each visualization here in Notebook itself. Also, make sure that it is well readable.\n",
    "#### (1) Top ~50% nodes, thrsholded by Node Degree\n",
    "#### (2) Top ~10% nodes, thrsholded by Node Degree\n",
    "#### (3) Top ~5% nodes, thrsholded by Node Degree\n",
    "#### (4) Top ~1% nodes, thrsholded by Node Degree\n",
    "#### (5) Top ~50% nodes, thrsholded by Betweeness Centrality\n",
    "#### (6) Top ~10% nodes, thrsholded by Betweeness Centrality\n",
    "#### (7) Top ~5% nodes, thrsholded by Betweeness Centrality\n",
    "#### (8) Top ~1% nodes, thrsholded by Betweeness Centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"SampleFilter.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your response images here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FACEBOOK DATASET - By Degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top ~1% nodes, thrsholded by Node Degree\n",
    "![Top ~1% nodes, thrsholded by Node Degree](images/fb1p.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top ~5% nodes, thrsholded by Node Degree\n",
    "![Top ~5% nodes, thrsholded by Node Degree](images/fb5p.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top ~10% nodes, thrsholded by Node Degree\n",
    "![Top ~10% nodes, thrsholded by Node Degree](images/fb10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top ~50% nodes, thrsholded by Node Degree\n",
    "![Top ~50% nodes, thrsholded by Node Degree](images/fb50.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facebook - By betweeness centrality\n",
    "### Note : 10% and 50% node filtering wasn't possible in Gephi for this dataset, hence 5% and 100% variations are provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top ~1% nodes, thrsholded by Betweeness Centrality\n",
    "![Top ~1% nodes, thrsholded by Betweeness Centrality](images/fb_ben_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top ~5% nodes, thrsholded by Betweeness Centrality\n",
    "![Top ~5% nodes, thrsholded by Betweeness Centrality](images/fb_ben_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top ~100% nodes, thrsholded by Betweeness Centrality\n",
    "![Top ~100% nodes, thrsholded by Betweeness Centrality](images/fb_ben_100.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enron - By node degree\n",
    "### Top ~1% nodes, thrsholded by Node Degree\n",
    "![Top ~1% nodes, thrsholded by Node Degree](images/enron1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top ~5% nodes, thrsholded by Node Degree\n",
    "![Top ~5% nodes, thrsholded by Node Degree](images/enron5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top ~10% nodes, thrsholded by Node Degree\n",
    "![Top ~10% nodes, thrsholded by Node Degree](images/enron10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top ~50% nodes, thrsholded by Node Degree\n",
    "![Top ~50% nodes, thrsholded by Node Degree](images/enron50.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enron - By betweeness centrality\n",
    "### Top ~1% nodes, thrsholded by betweeness centrality\n",
    "![Top ~1% nodes, thrsholded by betweeness centrality](images/enron1b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top ~5% nodes, thrsholded by betweeness centrality\n",
    "![Top ~5% nodes, thrsholded by betweeness centrality](images/enron5b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top ~10% nodes, thrsholded by betweeness centrality\n",
    "![Top ~10% nodes, thrsholded by betweeness centrality](images/enron10b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top ~50% nodes, thrsholded by betweeness centrality\n",
    "![Top ~50% nodes, thrsholded by betweeness centrality](images/enron50b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erdos - By node degree - \n",
    "### Note : 50% node filtering wasn't possible in Gephi for this dataset, hence 100% filtered variations are provided.\n",
    "### Top ~1% nodes, thrsholded by Node Degree\n",
    "![Top ~1% nodes, thrsholded by Node Degree](images/erdos1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top ~5% nodes, thrsholded by Node Degree\n",
    "![Top ~5% nodes, thrsholded by Node Degree](images/erdos5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top ~10% nodes, thrsholded by Node Degree\n",
    "![Top ~10% nodes, thrsholded by Node Degree](images/erdos10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top ~100% nodes, thrsholded by Node Degree\n",
    "![Top ~100% nodes, thrsholded by Node Degree](images/erdos100.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erdos - By betweeness centrality - \n",
    "### Note : 10%, 50% node filtering wasn't possible in Gephi for this dataset, hence 3.5% and 100% filtered variations are provided.\n",
    "### Top ~1% nodes, thrsholded by betweeness centrality\n",
    "![Top ~1% nodes, thrsholded by betweeness centrality](images/erdos1b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top ~3.5% nodes, thrsholded by betweeness centrality\n",
    "![Top ~3.5% nodes, thrsholded by betweeness centrality](images/erdos35b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top ~100% nodes, thrsholded by betweeness centrality\n",
    "![Top ~100% nodes, thrsholded by betweeness centrality](images/erdos100b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (B): Community Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this task, we will try to find communities in the given netwok and explore more about them. NetworkX has built in functions for community detection (http://perso.crans.org/aynaud/communities/). Along with NetworkX, we will also use igraph library in this task, for community detection purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#install required packages and read their documentation to get used to them.\n",
    "#!pip install community\n",
    "#!pip install igraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Community detection is a very common task for almost all networks. It helps us to understand network structure in much detail. \n",
    "#### More information on community detection: https://arxiv.org/abs/0906.0612"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are multiple algorithms to detect communities. One of the commonly used algorithm is Louvain method. The method is a greedy optimization method that attempts to optimize the \"modularity\" of a partition of the network. 'community' library uses Lovain algorithm, and hence we get partitions based on optimized modularity. Implement a python code using 'community' library to find communities in the Citation network and Collaboration Network (Erdos). Write your code in the next cell and visualize your community detection results in Gephi for both the networks. Label the nodes in the visualization properly. Use largest connected components, if required. Include image(.jpg, .png) of the visualization here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import community\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CitNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 27770\n",
      "Number of edges: 352807\n",
      "Average in degree:  12.7046\n",
      "Average out degree:  12.7046\n",
      "CPU times: user 2.03 s, sys: 112 ms, total: 2.14 s\n",
      "Wall time: 2.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# load the network\n",
    "file_name = \"../ece289_public/Cit-HepTh.txt\"\n",
    "# it's a directed graph, so we should use nx.DiGraph to read\n",
    "g1 = nx.read_edgelist(file_name, create_using=nx.DiGraph(), nodetype=int)\n",
    "print nx.info(g1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g2=g1.to_undirected()\n",
    "partition_citnet = community.best_partition(g2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g2=g1.to_undirected()\n",
    "deg = g2.degree()\n",
    "for k in g2.nodes():\n",
    "    g2.node[k]['comm'] = partition_citnet[k]\n",
    "    g2.node[k]['deg'] = deg[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import tarfile\n",
    "#tarfile.open(\"../ECE289_HW_1/data/citNet/cit-HepTh-abstracts.tar.gz\").extractall(\"../ECE289_HW_1/data/citNet/cit-HepTh-abstracts/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract the author name\n",
    "def get_authors(l):\n",
    "    authors = reduce(list.__add__, [a.split(\",\") for a in l[9:].split(\"and\")])\n",
    "    return [x.strip() for x in authors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# attach the attribute author\n",
    "#here G is your networkX graph\n",
    "import os\n",
    "for subdir, dirs, files in os.walk(\"../ECE289_HW_1/data/citNet/cit-HepTh-abstracts\"):\n",
    "    for fl in files:\n",
    "        filepath = subdir + os.sep + fl\n",
    "        \n",
    "        if filepath.endswith(\".abs\"):\n",
    "            node_num = int(fl[:-4])\n",
    "            name = \"\"\n",
    "            for l in open(filepath):\n",
    "                if l.startswith(\"Authors:\"):\n",
    "                    name = get_authors(l)[0]\n",
    "            if node_num in g2.nodes():\n",
    "                g2.node[node_num]['author'] = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': 'I. Chepelev', 'comm': 19, 'deg': 44}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g2.node[9701151]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nx.write_gml(g2, \"citNet_community.gml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erdos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 11524\n",
      "Number of edges: 18504\n",
      "Average degree:   3.2114\n"
     ]
    }
   ],
   "source": [
    "# build Collaboration Network\n",
    "# undirected network\n",
    "g1e = nx.Graph()\n",
    "\n",
    "# add Paul Erdos into our network at first\n",
    "dict_authors = {}\n",
    "dict_authors['Paul Erdos'] = 0\n",
    "g1e.add_node(0)\n",
    "g1e.node[0]['author'] = 'Paul Erdos'\n",
    "\n",
    "# add the authors with Erdos number 1 and 2 from file\n",
    "line_count = 1\n",
    "skip_line = 24\n",
    "skip_space = 1\n",
    "\n",
    "is_new = False\n",
    "author = \"\"\n",
    "coauthor = \"\"\n",
    "index = 1\n",
    "ind_author = 1\n",
    "ind_coauthor = 1\n",
    "\n",
    "def parseLine(l, start):\n",
    "    end = start\n",
    "    while end < len(l) - 1 and not (l[end] == ' ' and l[end + 1] == ' '):\n",
    "        end += 1\n",
    "    return l[start:end]\n",
    "\n",
    "def addAuthor(auth, ind):\n",
    "    if auth in dict_authors:\n",
    "        return ind\n",
    "    dict_authors[auth] = ind\n",
    "    return ind + 1\n",
    "\n",
    "for l in open(\"../ece289_public/Erdos.html\"):    \n",
    "    if line_count >= skip_line:\n",
    "        if l == '\\n':\n",
    "            is_new = True\n",
    "        elif is_new:\n",
    "            author = parseLine(l, 0)\n",
    "            index = addAuthor(author, index)\n",
    "            ind_author = dict_authors[author]\n",
    "            g1e.add_edge(0, ind_author)\n",
    "            g1e.node[ind_author]['author'] = author\n",
    "            is_new = False\n",
    "        elif l == '</pre>':\n",
    "            break\n",
    "        else:\n",
    "            coauthor = parseLine(l, skip_space)\n",
    "            index = addAuthor(coauthor, index)\n",
    "            ind_coauthor = dict_authors[coauthor]\n",
    "            g1e.add_edge(ind_author, ind_coauthor)\n",
    "            g1e.node[ind_coauthor]['author'] = coauthor\n",
    "    line_count += 1\n",
    "\n",
    "print nx.info(g1e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deg=g1e.degree()\n",
    "partition_erdos = community.best_partition(g1e)\n",
    "for k in g1e.nodes():\n",
    "    g1e.node[k]['deg'] = deg[k]\n",
    "    g1e.node[k]['comm'] = partition_erdos[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nx.write_gml(g1e, \"erdos_community.gml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citation network\n",
    "## View 1\n",
    "![community_detection_citation_network1](images/citnet3.png)\n",
    "## View 2\n",
    "![community_detection_citation_network2](images/citnet4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erdos network\n",
    "## View 1\n",
    "![community_detection_erdos_network1](images/erdos.png)\n",
    "## View 2\n",
    "![community_detection_erdos_network2](images/erdos3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compared to 'community' library, 'igraph' has more flexibilty to detect communities. igraph allows user to partition the network in the number of communities that user wishes. Obviously this number is bounded. Now, you will use this aspect to divide given network in '5' communities using 'igraph' and observe the results. Also, derive results for optimized modularity condition in igraph. Write a python code to implement above task for citation network & collaboration network (Erdos). Remember that unlike 'community', igraph has multiple approach for community detection. Obvious approach being greedy and it optimizes modularity. Visualize your community detection results in Gephi for both the networks. Label the nodes in the visualization properly. Use largest connected components, if required. Use different colors for nodes in every community. Include image(.jpg, .png) of the visualization here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from igraph import *\n",
    "\n",
    "#your code here\n",
    "\n",
    "#partition network using greedy approach. Note the number of communities\n",
    "\n",
    "#partition network in 5 communities and see the difference in the visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erdos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGRAPH U--- 11524 18504 -- \n",
      "+ attr: author (v), comm (v), deg (v), id (v), label (v)\n"
     ]
    }
   ],
   "source": [
    "gi1 = Graph.Read_GML('erdos_community.gml')\n",
    "igraph.summary(gi1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "com_1 = gi1.simplify().community_fastgreedy().as_clustering()\n",
    "mem = com_1.membership\n",
    "for i in range(0,len(mem)):\n",
    "    gi1.vs[i]['igraph_com'] = mem[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The numbers of clusters by optimizing modularity is for Erdos n/w is 58\n"
     ]
    }
   ],
   "source": [
    "print 'The numbers of clusters by optimizing modularity is for Erdos n/w is',len(com_1.subgraphs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gi1.write_gml('gi1_erdos.gml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized modularity - clusters\n",
    "![Optimized modularity - clusters](images/erdos_igraph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erdos - 5 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "com_e5 = gi1.simplify().community_fastgreedy().as_clustering(n=5)\n",
    "mem = com_e5.membership\n",
    "for i in range(0,len(mem)):\n",
    "    gi1.vs[i]['igraph_com'] = mem[i]\n",
    "gi1.write_gml('gi1_clus5_erdos.gml')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 clusters\n",
    "![5 clusters](images/erdos_clus5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gic2  = Graph.Read_GML('citNet_community.gml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "com_c = gic2.simplify().community_fastgreedy().as_clustering()\n",
    "mem = com_c.membership\n",
    "#len(mem)\n",
    "#len(gi1.degree())\n",
    "#gi2.vs[0]\n",
    "for i in range(0,len(mem)):\n",
    "    gic2.vs[i]['igraph_com'] = mem[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The numbers of clusters by optimizing modularity is for Citation n/w is 285\n"
     ]
    }
   ],
   "source": [
    "#gic2.vs[1000]\n",
    "#summary(gic2)\n",
    "print 'The numbers of clusters by optimizing modularity is for Citation n/w is',len(com_c.subgraphs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gic2.write_gml('gic2_citnet.gml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized modularity - clusters\n",
    "![Optimized modularity - clusters](images/citnet1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CitNet - 5 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "com_c = gic2.simplify().community_fastgreedy()\n",
    "#mem = com_c.membership\n",
    "#len(mem)\n",
    "#len(gi1.degree())\n",
    "#gi2.vs[0]\n",
    "#for i in range(0,len(mem)):\n",
    "#    gic2.vs[i]['igraph_com'] = mem[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The clustering for 5 clusters doesn't work. Error due to small merge matrices.\n",
    "### So, we take larger clusters and trim it to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Error at community.c:769: `steps' to big or `merges' matrix too short, Invalid value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-200-7373f3d04860>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcomc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_clustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/python2/lib/python2.7/site-packages/igraph/clustering.pyc\u001b[0m in \u001b[0;36mas_clustering\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    975\u001b[0m         \u001b[0midgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUniqueIdGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m         membership = community_to_membership(self._merges, num_elts, \\\n\u001b[0;32m--> 977\u001b[0;31m                                              num_elts - n)\n\u001b[0m\u001b[1;32m    978\u001b[0m         \u001b[0mmembership\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0midgen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmembership\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m         return VertexClustering(self._graph, membership,\n",
      "\u001b[0;31mInternalError\u001b[0m: Error at community.c:769: `steps' to big or `merges' matrix too short, Invalid value"
     ]
    }
   ],
   "source": [
    "#comc1 = com_c.as_clustering(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comc1 = com_c.as_clustering(n=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,c in enumerate(comc1):\n",
    "    if i<6:\n",
    "        for k in c:\n",
    "            gic2.vs[k]['igraph_com'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gic2.write_gml('gic2_clus5_citnet.gml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 clusters\n",
    "![5 clusters](images/citnet_clus5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we have detected communities, we will further analyze our results. This task is only for Collaboration network (Erdos). Use results from communtiy detection using 'community'. Sort communities and get largest 5 communities. For each of these 5 communities, get 3 nodes with the highest node degree. So you will get 3 authors per community, for 5 communities. Now search the area of research for each of these authors and enlist them. Further, observe if there is any reason for those 3 authors to be in same community, for each community. State that reason in brief. Write all of your results in next cell. Also include any other interesting results that you may observe during process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#your observations here\n",
    "# 'g1e' contains the erdos graph as a networx graph\n",
    "l = len(g1e.node)\n",
    "c = []\n",
    "for i in range(0,l):\n",
    "    c.append(g1e.node[i]['comm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 communities in erdos graph are :\n",
      "Community (Count)\n",
      "11 \t  (1079)\n",
      "5 \t  (1050)\n",
      "14 \t  (891)\n",
      "0 \t  (638)\n",
      "17 \t  (621)\n"
     ]
    }
   ],
   "source": [
    "print 'The top 5 communities in erdos graph are :'\n",
    "print 'Community (Count)'\n",
    "coms = []\n",
    "for count, elem in sorted(((c.count(e), e) for e in set(c)), reverse=True)[:5]:\n",
    "    print '%s \\t  (%d)' % (elem, count)\n",
    "    coms.append(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 3 authors in the community  11 are : \n",
      "\t Author : HARARY, FRANK* with degree : 316\n",
      "\t Author : GRAHAM, RONALD LEWIS with degree : 197\n",
      "\t Author : CHUNG, FAN RONG KING (GRAHAM) with degree : 143\n",
      "\n",
      "\n",
      "The top 3 authors in the community  5 are : \n",
      "\t Author : LUCA, FLORIAN with degree : 194\n",
      "\t Author : SHALLIT, JEFFREY OUTLAW with degree : 127\n",
      "\t Author : POMERANCE, CARL BERNARD with degree : 113\n",
      "\n",
      "\n",
      "The top 3 authors in the community  14 are : \n",
      "\t Author : ALON, NOGA M. with degree : 436\n",
      "\t Author : LOVASZ, LASZLO with degree : 146\n",
      "\t Author : SAKS, MICHAEL EZRA with degree : 141\n",
      "\n",
      "\n",
      "The top 3 authors in the community  0 are : \n",
      "\t Author : Paul Erdos with degree : 511\n",
      "\t Author : STRAUS, ERNST GABOR* with degree : 71\n",
      "\t Author : CHOWLA, SARVADAMAN D. S.* with degree : 68\n",
      "\n",
      "\n",
      "The top 3 authors in the community  17 are : \n",
      "\t Author : TUZA, ZSOLT with degree : 224\n",
      "\t Author : PACH, JANOS with degree : 155\n",
      "\t Author : ARONOV, BORIS with degree : 120\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "listofnodes = list([i for i in g1e.__iter__()])\n",
    "for ci in coms:\n",
    "    nodes = list(filter(lambda k : g1e.node[k]['comm'] == ci,listofnodes))\n",
    "    lisofdeg = sorted([(g1e.node[i]['deg'],i) for i in nodes], reverse=True)[:3]\n",
    "    nodelists = [g1e.node[i[1]] for i in lisofdeg]\n",
    "    print 'The top 3 authors in the community ',ci,'are : '\n",
    "    for i in nodelists:\n",
    "        print '\\t Author : %s with degree : %d' % (i['author'],i['deg'])\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Interesting observation : Nearly most of the authors have some relation with Erdos graph theory, and have either wrote papers with him or have proved his conjectures etc, which makes sense since it is a Erdos dataset we have.\n",
    "##### 2. Also many people do publish in combinatrics, which is visible across clusters, and since they have max. degree; it means that a lot of papers are published in combinatorics, or atleast by the people associated with Erdos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Community 11\n",
    "\n",
    "Harary Frank : Frank Harary was an American mathematician, who specialized in graph theory. He was widely recognized as one of the \"fathers\" of modern graph theory.\n",
    "\n",
    "graham ronald lewis : Ronald Lewis \"Ron\" Graham (born October 31, 1935) is a mathematician credited by the American Mathematical Society as being \"one of the principal architects of the rapid development worldwide of discrete mathematics in recent years\". He has done important work in scheduling theory, computational geometry, Ramsey theory, and quasi-randomness.\n",
    "\n",
    "Fan Ron King Chung : Fan-Rong King Chung Graham (Chinese: 金芳蓉; pinyin: Jīn Fāngróng; born October 9, 1949), known professionally as Fan Chung, is a mathematician who works mainly in the areas of spectral graph theory, extremal graph theory and random graphs, in particular in generalizing the Erdős–Rényi model for graphs with general degree distribution (including power-law graphs in the study of large information networks).\n",
    "\n",
    "#### As we can see, all the 3 authors in the above community have worked in GRAPH THEORY, especially in discrete math."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Community 5\n",
    "\n",
    "Luca Florian : Florian Luca (born 16 March 1969 in Galați) is a Romanian mathematician who specializes in number theory with emphasis on Diophantine equations, linear recurrences and the distribution of values of arithmetic functions. He has made notable contributions to the proof that irrational automatic numbers are transcendental and the proof of a conjecture of Erdős on the intersection of the Euler function and the sum of divisors function.\n",
    "\n",
    "SHALLIT, JEFFREY OUTLAW : Jeffrey Outlaw Shallit (born October 17, 1957) is a computer scientist, number theorist, a noted advocate for civil liberties on the Internet, and a noted critic of intelligent design. He is married to Anna Lubiw, also a computer scientist.\n",
    "\n",
    "POMERANCE, CARL BERNARD : Carl Bernard Pomerance (born in 1944 in Joplin, Missouri) is an American number theorist. He attended college at Brown University and later received his Ph.D. from Harvard University in 1972 with a dissertation proving that any odd perfect number has at least seven distinct prime factors.[1] He immediately joined the faculty at the University of Georgia, becoming full professor in 1982. He subsequently worked at Lucent Technologies for a number of years, and then became a distinguished Professor at Dartmouth College.\n",
    "\n",
    "#### As we can see, all the 3 authors are working in number theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Community 14 \n",
    "\n",
    "ALON, NOGA M. : Combinatorics, Graph Theory and their applications to Theoretical Computer Science. Combinatorial algorithms and circuit complexity. Combinatorial geometry and Combinatorial number theory. Algebraic and probabilistic methods in Combinatorics.\n",
    "\n",
    "LOVASZ, LASZLO : László Lovász is a Hungarian mathematician, best known for his work in combinatorics, for which he was awarded the Wolf Prize and the Knuth Prize in 1999, and the Kyoto Prize in 2010. He is the current president of the Hungarian Academy of Sciences.\n",
    "\n",
    "SAKS, MICHAEL EZRA : Saks research in computational complexity theory, combinatorics, and graph theory has contributed to the study of lower bounds in order theory, randomized computation, and space-time tradeoff.\n",
    "\n",
    "#### As we can see, all the 3 authors are working in combinatrics, graph theory and theortical computer science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Community 0 \n",
    "\n",
    "Paul Erdos : Erdős pursued and proposed problems in discrete mathematics, graph theory, number theory, mathematical analysis, approximation theory, set theory, and probability theory.\n",
    "\n",
    "STRAUS, ERNST GABOR* : Ernst Gabor Straus (February 25, 1922 – July 12, 1983) was a German-American mathematician of Jewish origin who helped found the theories of Euclidean Ramsey theory and of the arithmetic properties of analytic functions. His extensive list of co-authors includes Albert Einstein, Paul Erdős, Richard Bellman, Béla Bollobás, Sarvadaman Chowla, Ronald Graham, László Lovász, Carl Pomerance, and George Szekeres.\n",
    "\n",
    "CHOWLA, SARVADAMAN D. S.* : Sarvadaman D. S. Chowla (22 October 1907 – 10 December 1995) was a British-born Indian American mathematician, specializing in number theory. Among his contributions are a number of results which bear his name. These include the Bruck–Ryser–Chowla theorem, the Ankeny–Artin–Chowla congruence, the Chowla–Mordell theorem, and the Chowla–Selberg formula, and the Mian–Chowla sequence.\n",
    "\n",
    "#### As we can see, we have the main man, Dr. Erdos in this community, and he shares the community with other erdos'ists, who have worked with him in number theory, ramsey theory and discrete math."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Community 17 : \n",
    "\n",
    "TUZA, ZSOLT : Upenn guy. Graph theory, combinatrics, hypergraphs etc\n",
    "\n",
    "PACH, JANOS : János Pach (born May 3, 1954)[2] is a mathematician and computer scientist working in the fields of combinatorics and discrete and computational geometry.\n",
    "\n",
    "ARONOV, BORIS :  Boris Aronov is a computer scientist, currently a professor at the Tandon School of Engineering, New York University. His main area of research is computational geometry. He is a Sloan Research Fellow. \n",
    "\n",
    "#### As we can see we have computer scientists in the field of combinatorics in this cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
